{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08c1873",
   "metadata": {},
   "source": [
    "Fitche data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce98965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Order_ID                1000 non-null   int64  \n",
      " 1   Distance_km             1000 non-null   float64\n",
      " 2   Weather                 970 non-null    object \n",
      " 3   Traffic_Level           970 non-null    object \n",
      " 4   Time_of_Day             970 non-null    object \n",
      " 5   Vehicle_Type            1000 non-null   object \n",
      " 6   Preparation_Time_min    1000 non-null   int64  \n",
      " 7   Courier_Experience_yrs  970 non-null    float64\n",
      " 8   Delivery_Time_min       1000 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 70.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_ID</th>\n",
       "      <th>Distance_km</th>\n",
       "      <th>Preparation_Time_min</th>\n",
       "      <th>Courier_Experience_yrs</th>\n",
       "      <th>Delivery_Time_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>970.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>500.500000</td>\n",
       "      <td>10.059970</td>\n",
       "      <td>16.982000</td>\n",
       "      <td>4.579381</td>\n",
       "      <td>56.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288.819436</td>\n",
       "      <td>5.696656</td>\n",
       "      <td>7.204553</td>\n",
       "      <td>2.914394</td>\n",
       "      <td>22.070915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>250.750000</td>\n",
       "      <td>5.105000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>500.500000</td>\n",
       "      <td>10.190000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>55.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>750.250000</td>\n",
       "      <td>15.017500</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>153.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Order_ID  Distance_km  Preparation_Time_min  Courier_Experience_yrs  \\\n",
       "count  1000.000000  1000.000000           1000.000000              970.000000   \n",
       "mean    500.500000    10.059970             16.982000                4.579381   \n",
       "std     288.819436     5.696656              7.204553                2.914394   \n",
       "min       1.000000     0.590000              5.000000                0.000000   \n",
       "25%     250.750000     5.105000             11.000000                2.000000   \n",
       "50%     500.500000    10.190000             17.000000                5.000000   \n",
       "75%     750.250000    15.017500             23.000000                7.000000   \n",
       "max    1000.000000    19.990000             29.000000                9.000000   \n",
       "\n",
       "       Delivery_Time_min  \n",
       "count        1000.000000  \n",
       "mean           56.732000  \n",
       "std            22.070915  \n",
       "min             8.000000  \n",
       "25%            41.000000  \n",
       "50%            55.500000  \n",
       "75%            71.000000  \n",
       "max           153.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "path = \"/Users/lait-zet/Desktop/Work_local/Data/data_livre.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "olddata = df\n",
    "df.head(4)\n",
    "df.info()\n",
    "df.isnull().sum()\n",
    "df.duplicated().sum()\n",
    "df.describe()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d32d694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order_ID                   0\n",
       "Distance_km                0\n",
       "Weather                   30\n",
       "Traffic_Level             30\n",
       "Time_of_Day               30\n",
       "Vehicle_Type               0\n",
       "Preparation_Time_min       0\n",
       "Courier_Experience_yrs    30\n",
       "Delivery_Time_min          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b83ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing(df, columns):\n",
    "    i = 0\n",
    "    while i < len(columns):\n",
    "        col = columns[i]\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        else:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        i += 1\n",
    "    return df\n",
    "convert_columns = ['Weather', 'Traffic_Level', 'Time_of_Day', 'Courier_Experience_yrs']\n",
    "df = handle_missing(df, convert_columns)\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd926770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(df):\n",
    "    return df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "def is_categorie(df):\n",
    "    return df.select_dtypes(exclude=['int64', 'float64'])\n",
    "Data_Numeric = is_numeric(df)\n",
    "Data_categorie = is_categorie(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f79054",
   "metadata": {},
   "source": [
    "Visulisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0900f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = Data_Numeric.corr()\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.heatmap(corr, vmax=1 , vmin=-1 , annot=True)\n",
    "# plt.title('Heatmap de corrélation des variables numériques')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86326fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_cols = ['Weather', 'Traffic_Level','Time_of_Day', 'Vehicle_Type']\n",
    "# olddata\n",
    "# for col in categorical_cols:\n",
    "#     sns.countplot(x = col , data = olddata , palette='husl')\n",
    "#     plt.title(f\"distribution : {col}\")\n",
    "#     plt.xlabel(col)\n",
    "#     plt.ylabel(\"Count\")\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15596baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cols in categorical_cols:\n",
    "#     sns.boxplot(x = cols ,y = 'Delivery_Time_min' ,data = df ,palette='Set2')\n",
    "#     plt.title(f\"Relation between {cols} and Dilvery time\")\n",
    "#     plt.xlabel(col)\n",
    "#     plt.ylabel(\"Delivery Time\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a7fe2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6,4))\n",
    "# sns.histplot(df['Delivery_Time_min'], bins=20, kde=True, color='skyblue')\n",
    "# plt.title(\"Distribution de la variable cible : Delivery_Time_min\")\n",
    "# plt.xlabel(\"Delivery Time (min)\")\n",
    "# plt.ylabel(\"Fréquence\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e5951d",
   "metadata": {},
   "source": [
    "Split_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50697a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = Data_Numeric[['Distance_km','Preparation_Time_min']]\n",
    "cat_data =Data_categorie[['Weather','Traffic_Level']]\n",
    "def use_scled(data):\n",
    "    le = StandardScaler()\n",
    "    scaled = le.fit_transform(data)\n",
    "    scaled_numerique = pd.DataFrame(scaled, columns=data.columns)\n",
    "    return scaled_numerique\n",
    "def use_hote(data):\n",
    "    la = OneHotEncoder(sparse_output=False)\n",
    "    encoded = la.fit_transform(data)\n",
    "    cooder_categorie = pd.DataFrame(encoded,columns = la.get_feature_names_out(data.columns))\n",
    "    return cooder_categorie\n",
    "cooder_categorie = use_hote(cat_data)\n",
    "scaled_numerique = use_scled(num_data)\n",
    "# cooder_categorie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8b4365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['Delivery_Time_min']\n",
    "prepared_data = pd.concat(\n",
    "    [scaled_numerique, cooder_categorie, target],\n",
    "    axis=1\n",
    ")\n",
    "X = df.drop(columns=[\"Delivery_Time_min\"])\n",
    "Y = df['Delivery_Time_min']\n",
    "def split_data(df):\n",
    "    X = df.drop(columns=[\"Delivery_Time_min\"])\n",
    "    Y = df['Delivery_Time_min']\n",
    "    train_X , test_X , train_Y , test_Y = train_test_split(\n",
    "    X , Y , test_size=0.2, random_state=42\n",
    "    )\n",
    "    return train_X,test_X,train_Y,test_Y\n",
    "\n",
    "train_X,test_X,train_Y,test_Y = split_data(prepared_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c43b3",
   "metadata": {},
   "source": [
    "SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a26bf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Windy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/var/folders/34/r9gx_24s3cn901gzyz1dpgm80000gn/T/ipykernel_10455/2547495998.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m selector = SelectKBest(score_func = f_classif ,k=\u001b[32m3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m x_new = selector.fit_transform(X,Y)\n\u001b[32m      3\u001b[39m mask = selector.get_support()\n\u001b[32m      4\u001b[39m mask\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col, score \u001b[38;5;28;01min\u001b[39;00m zip(X.columns, selector.scores_):\n",
      "\u001b[32m~/Desktop/Delivery-Time-Prediction/.venv/lib/python3.13/site-packages/sklearn/utils/_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m     @wraps(f)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    318\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m             return_tuple = (\n",
      "\u001b[32m~/Desktop/Delivery-Time-Prediction/.venv/lib/python3.13/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    893\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m    894\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    895\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32m~/Desktop/Delivery-Time-Prediction/.venv/lib/python3.13/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~/Desktop/Delivery-Time-Prediction/.venv/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    559\u001b[39m         \"\"\"\n\u001b[32m    560\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    561\u001b[39m             X = validate_data(self, X, accept_sparse=[\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m])\n\u001b[32m    562\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m             X, y = validate_data(\n\u001b[32m    564\u001b[39m                 self, X, y, accept_sparse=[\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m], multi_output=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    565\u001b[39m             )\n\u001b[32m    566\u001b[39m \n",
      "\u001b[32m~/Desktop/Delivery-Time-Prediction/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2967\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2968\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2969\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2972\u001b[39m         out = X, y\n\u001b[32m   2973\u001b[39m \n\u001b[32m   2974\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32m~/Desktop/Delivery-Time-Prediction/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m         )\n\u001b[32m   1365\u001b[39m \n\u001b[32m   1366\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1367\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     X = check_array(\n\u001b[32m   1369\u001b[39m         X,\n\u001b[32m   1370\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1371\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32m~/Desktop/Delivery-Time-Prediction/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32m~/Desktop/Delivery-Time-Prediction/.venv/lib/python3.13/site-packages/sklearn/utils/_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~/Desktop/Delivery-Time-Prediction/.venv/lib/python3.13/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Windy'"
     ]
    }
   ],
   "source": [
    "# selector = SelectKBest(score_func = f_classif ,k=3)\n",
    "# x_new = selector.fit_transform(X,Y)\n",
    "# mask = selector.get_support()\n",
    "# mask\n",
    "# for col, score in zip(X.columns, selector.scores_):\n",
    "#     print(f\"{col}: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc8e34",
   "metadata": {},
   "source": [
    "GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00061cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d889c7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "Random Forest - MAE: 6.982, R²: 0.790\n",
      "SVR            - MAE:  5.990, R²: 0.817\n",
      "\n",
      "final choisi est: SVR (Support Vector Regressor)\n"
     ]
    }
   ],
   "source": [
    "def GridSearch_CV(trainX, testX ,trainY ,testY):\n",
    "    RF = RandomForestRegressor()\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', 1.0]\n",
    "    }\n",
    "    grid_search_for_RF = GridSearchCV(\n",
    "        estimator = RF,\n",
    "        param_grid = param_grid,\n",
    "        scoring='r2',\n",
    "        cv = 5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    grid_search_for_RF.fit(train_X,train_Y)\n",
    "    best_RF = grid_search_for_RF.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "    svr = SVR()\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "    grid_search_for_SVC = GridSearchCV(\n",
    "        estimator = svr,\n",
    "        param_grid = param_grid,\n",
    "        cv = 5,\n",
    "        scoring='r2',\n",
    "        verbose= 0\n",
    "    )\n",
    "    grid_search_for_SVC.fit(train_X,train_Y)\n",
    "    best_SVR = grid_search_for_SVC.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "    pred_RF = best_RF.predict(test_X)\n",
    "    pred_SVR = best_SVR.predict(test_X)\n",
    "\n",
    "    mae_RF = mean_absolute_error(test_Y, pred_RF)\n",
    "    r2_RF = r2_score(test_Y, pred_RF)\n",
    "\n",
    "    mae_SVR = mean_absolute_error(test_Y, pred_SVR)\n",
    "    r2_SVR = r2_score(test_Y, pred_SVR)\n",
    "\n",
    "    print(f\"Random Forest - MAE: {mae_RF:.3f}, R²: {r2_RF:.3f}\")\n",
    "    print(f\"SVR            - MAE: {mae_SVR : .3f}, R²: {r2_SVR:.3f}\")\n",
    "\n",
    "    if r2_RF > r2_SVR:\n",
    "        print(\"\\n final choisi est: Random Forest Regressor\")\n",
    "    else:\n",
    "        print(\"\\nfinal choisi est: SVR (Support Vector Regressor)\")\n",
    "    return {\n",
    "        \"RandomForestRegressor\" : {\"MAE\":mae_RF, \"r_2\" : r2_RF},\n",
    "        \"SVR\" : {\"MAE\":mae_RF, \"r_2\" : r2_SVR}\n",
    "    }\n",
    "result = GridSearch_CV(train_X,test_X, train_Y,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc268de6",
   "metadata": {},
   "source": [
    "Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd01182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
